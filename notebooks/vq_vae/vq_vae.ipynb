{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.CIFAR10(root='../data',\n",
    "                                 train=True,\n",
    "                                 download=True,\n",
    "                                 transform=transforms.Compose([\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize((0.5, 0.5, 0.5), (1.0, 1.0, 1.0))\n",
    "                                 ]))\n",
    "\n",
    "validation_data = datasets.CIFAR10(root='../data',\n",
    "                                   train=False,\n",
    "                                   download=True,\n",
    "                                   transform=transforms.Compose([\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize((0.5, 0.5, 0.5), (1.0, 1.0, 1.0))\n",
    "                                   ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_variance = np.var(training_data.data / 255.0)\n",
    "data_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loader = DataLoader(training_data, batch_size=256, shuffle=True, num_workers=8, pin_memory=True)\n",
    "validation_loader = DataLoader(validation_data, batch_size=32, shuffle=True, num_workers=8, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = iter(training_loader).next()\n",
    "batch[0].shape, batch[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Residual(nn.Module):\n",
    "    def __init__(self, in_channels, num_hiddens, num_residual_hiddens):\n",
    "        super(Residual, self).__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(in_channels=in_channels,\n",
    "                      out_channels=num_residual_hiddens,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1,\n",
    "                      bias=False), nn.ReLU(True),\n",
    "            nn.Conv2d(in_channels=num_residual_hiddens,\n",
    "                      out_channels=num_hiddens,\n",
    "                      kernel_size=1,\n",
    "                      stride=1,\n",
    "                      bias=False))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.block(x)\n",
    "\n",
    "\n",
    "class ResidualStack(nn.Module):\n",
    "    def __init__(self, in_channels, num_hiddens, num_residual_layers, num_residual_hiddens):\n",
    "        super(ResidualStack, self).__init__()\n",
    "        self.num_residual_layers = num_residual_layers\n",
    "        self.layers = nn.ModuleList([\n",
    "            Residual(in_channels, num_hiddens, num_residual_hiddens)\n",
    "            for _ in range(self.num_residual_layers)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i in range(self.num_residual_layers):\n",
    "            x = self.layers[i](x)\n",
    "        return F.relu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, in_channels, num_hiddens, num_residual_layers, num_residual_hiddens):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.conv_1 = nn.Conv2d(in_channels=in_channels,\n",
    "                                out_channels=num_hiddens // 2,\n",
    "                                kernel_size=4,\n",
    "                                stride=2,\n",
    "                                padding=1)\n",
    "        self.conv_2 = nn.Conv2d(in_channels=num_hiddens // 2,\n",
    "                                out_channels=num_hiddens,\n",
    "                                kernel_size=4,\n",
    "                                stride=2,\n",
    "                                padding=1)\n",
    "        self.conv_3 = nn.Conv2d(in_channels=num_hiddens,\n",
    "                                out_channels=num_hiddens,\n",
    "                                kernel_size=3,\n",
    "                                stride=1,\n",
    "                                padding=1)\n",
    "        self.residual_stack = ResidualStack(in_channels=num_hiddens,\n",
    "                                            num_hiddens=num_hiddens,\n",
    "                                            num_residual_layers=num_residual_layers,\n",
    "                                            num_residual_hiddens=num_residual_hiddens)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.conv_1(inputs)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv_2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv_3(x)\n",
    "        return self.residual_stack(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, in_channels, num_hiddens, num_residual_layers, num_residual_hiddens):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.conv_1 = nn.Conv2d(in_channels=in_channels,\n",
    "                                out_channels=num_hiddens,\n",
    "                                kernel_size=3,\n",
    "                                stride=1,\n",
    "                                padding=1)\n",
    "\n",
    "        self.residual_stack = ResidualStack(in_channels=num_hiddens,\n",
    "                                            num_hiddens=num_hiddens,\n",
    "                                            num_residual_layers=num_residual_layers,\n",
    "                                            num_residual_hiddens=num_residual_hiddens)\n",
    "\n",
    "        self.conv_trans_1 = nn.ConvTranspose2d(in_channels=num_hiddens,\n",
    "                                               out_channels=num_hiddens // 2,\n",
    "                                               kernel_size=4,\n",
    "                                               stride=2,\n",
    "                                               padding=1)\n",
    "\n",
    "        self.conv_trans_2 = nn.ConvTranspose2d(in_channels=num_hiddens // 2,\n",
    "                                               out_channels=3,\n",
    "                                               kernel_size=4,\n",
    "                                               stride=2,\n",
    "                                               padding=1)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.conv_1(inputs)\n",
    "        x = self.residual_stack(x)\n",
    "        x = self.conv_trans_1(x)\n",
    "        x = F.relu(x)\n",
    "        return self.conv_trans_2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorQuantizer(nn.Module):\n",
    "    def __init__(self, num_embeddings, embedding_dim, commitment_cost):\n",
    "        super(VectorQuantizer, self).__init__()\n",
    "\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_embeddings = num_embeddings\n",
    "\n",
    "        self.embedding = nn.Embedding(self.num_embeddings, self.embedding_dim)\n",
    "        self.embedding.weight.data.uniform_(-1/self.num_embeddings, 1/self.num_embeddings)\n",
    "        self.commitment_cost = commitment_cost\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # convert inputs from BCHW -> BHWC\n",
    "        inputs = inputs.permute(0, 2, 3, 1).contiguous()\n",
    "        input_shape = inputs.shape\n",
    "\n",
    "        # Flatten input\n",
    "        flat_input = inputs.view(-1, self.embedding_dim)\n",
    "\n",
    "        # Calculate distances\n",
    "        distances = (torch.sum(flat_input**2, dim=1, keepdim=True)\n",
    "                    + torch.sum(self.embedding.weight**2, dim=1)\n",
    "                    - 2 * torch.matmul(flat_input, self.embedding.weight.t()))\n",
    "\n",
    "        # Encoding\n",
    "        encoding_indices = torch.argmin(distances, dim=1).unsqueeze(1)\n",
    "        encodings = torch.zeros(encoding_indices.shape[0], self.num_embeddings, device=inputs.device)\n",
    "        encodings.scatter_(1, encoding_indices, 1)\n",
    "\n",
    "        # Quantize and unflatten\n",
    "        quantized = torch.matmul(encodings, self.embedding.weight).view(input_shape)\n",
    "\n",
    "        # Loss\n",
    "        e_latent_loss = F.mse_loss(quantized.detach(), inputs)\n",
    "        q_latent_loss = F.mse_loss(quantized, inputs.detach())\n",
    "        vq_loss = q_latent_loss + self.commitment_cost * e_latent_loss\n",
    "\n",
    "        quantized = inputs + (quantized - inputs).detach()\n",
    "        avg_probs = torch.mean(encodings, dim=0)\n",
    "        perplexity = torch.exp(-torch.sum(avg_probs * torch.log(avg_probs + 1e-10)))\n",
    "\n",
    "        # convert quantized from BHWC -> BCHW\n",
    "        return vq_loss, quantized.permute(0, 3, 1, 2).contiguous(), perplexity, encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_training_updates = 15000\n",
    "\n",
    "num_hiddens = 128\n",
    "num_residual_hiddens = 32\n",
    "num_residual_layers = 2\n",
    "embedding_dim = 64\n",
    "num_embeddings = 512\n",
    "\n",
    "commitment_cost = 0.25\n",
    "decay = 0.99\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(pl.LightningModule):\n",
    "    def __init__(self,\n",
    "                 num_hiddens,\n",
    "                 num_residual_layers,\n",
    "                 num_residual_hiddens,\n",
    "                 num_embeddings,\n",
    "                 embedding_dim,\n",
    "                 commitment_cost):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        self.encoder = Encoder(3, num_hiddens, num_residual_layers, num_residual_hiddens)\n",
    "        self.pre_vq_conv = nn.Conv2d(in_channels=num_hiddens,\n",
    "                                      out_channels=embedding_dim,\n",
    "                                      kernel_size=1,\n",
    "                                      stride=1)\n",
    "        self.vq_vae = VectorQuantizer(num_embeddings, embedding_dim, commitment_cost)\n",
    "        self.decoder = Decoder(embedding_dim, num_hiddens, num_residual_layers,\n",
    "                                num_residual_hiddens)\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        z = self.pre_vq_conv(z)\n",
    "        vq_loss, quantized, perplexity, _ = self.vq_vae(z)\n",
    "        x_recon = self.decoder(quantized)\n",
    "        return vq_loss, x_recon, perplexity\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=learning_rate, amsgrad=False)\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        data, _ = train_batch\n",
    "\n",
    "        vq_loss, data_recon, perplexity = self.forward(data)\n",
    "        recon_error = F.mse_loss(data_recon, data) / data_variance\n",
    "        loss = recon_error + vq_loss\n",
    "\n",
    "        self.log('train/recon_error', recon_error)\n",
    "        self.log('train/vq_loss', vq_loss)\n",
    "        self.log('train/perplexity', perplexity)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(num_hiddens, num_residual_layers, num_residual_hiddens, num_embeddings, embedding_dim,\n",
    "              commitment_cost)\n",
    "tb_logger = TensorBoardLogger('../../lightning_logs', name='vq_vae_cifar10', default_hp_metric=False)\n",
    "trainer = pl.Trainer(gpus=[0], logger=tb_logger, max_steps=15000)\n",
    "trainer.fit(model, training_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import make_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_originals, _ = next(iter(validation_loader))\n",
    "_, valid_recons, _ = model(valid_originals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(img):\n",
    "    npimg = img.numpy()\n",
    "    fig = plt.imshow(np.transpose(npimg, (1, 2, 0)), interpolation='nearest')\n",
    "    fig.axes.get_xaxis().set_visible(False)\n",
    "    fig.axes.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(make_grid(valid_recons.cpu().data) + 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(make_grid(valid_originals.cpu().data) + 0.5)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "269a05f21f9d472e9e5e31559938815b8fb99361761e8a3fc4370b626fe386c7"
  },
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
